{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defines directories and credent\n",
    "execfile('theStuff.py')\n",
    "\n",
    "import psycopg2\n",
    "import getpass\n",
    "import psycopg2.extras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conn_string = \"host='localhost' dbname=\" + str(database) + \" user=\" + str(pgu) + \" password=\" + str(passpg)\n",
    "\n",
    "conn= psycopg2.connect(conn_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifies proper nouns in sentences containing word dam.  This can be used to query dam names, stream names, states and alike\n",
    "# that may help to identify main dam removal(s) referenced in a paper.\n",
    "\n",
    "def properNouns(cursor):\n",
    "    d = []\n",
    "    #Requires cursor from postgres query of initial NLP data from UW database\n",
    "    for sentence in cursor:\n",
    "        #Identify fields within cursor\n",
    "        docid = sentence[0]\n",
    "        sentid = sentence[1]\n",
    "        words = sentence[3]\n",
    "        poses = sentence[4]\n",
    "        index_num = len(poses)   # Set index for total number of items within sentence\n",
    "        \n",
    "        ####################################################################################################\n",
    "        ###Loop through each sentence item################################################################## \n",
    "        #if Proper Noun return docid, sentid, begin_index, end_index, and entire string of Proper Noun Words\n",
    "        ###################################################################################################\n",
    "        \n",
    "        for i in xrange(index_num): \n",
    "            #try used to catch first iteration where end_index is not currently defined\n",
    "            try:   \n",
    "                # If catches all Proper Nouns that are more than one word, elif catches Proper Nouns = 1 word\n",
    "                # if and elif require end index to be less than index so partial string of Proper Nouns are not captured \n",
    "                # where end_index is greater than index continue to next index value in sentence \n",
    "                if i > end_index and poses[i] == \"NNP\" and poses[i+1] == 'NNP':\n",
    "                    end_index = i + 1\n",
    "                    proper_noun = words[i]\n",
    "                    while end_index < index_num and (poses[end_index] == \"NNP\"):\n",
    "                        proper_noun += (\" \" + words[end_index])\n",
    "                        mention_id = \"%s_%d_%d_%d\" % (docid, sentid, i, end_index)\n",
    "                        end_index += 1\n",
    "                elif i > end_index and poses[i] == \"NNP\":\n",
    "                    end_index = i \n",
    "                    mention_id = \"%s_%d_%d_%d\" % (docid, sentid, i, end_index)\n",
    "                    proper_noun = words[i]\n",
    "                else:\n",
    "                    continue\n",
    "            except:\n",
    "                if poses[i] == \"NNP\" and poses[i+1] == 'NNP':\n",
    "                    end_index = i + 1\n",
    "                    proper_noun = words[i]\n",
    "                    while end_index < index_num and (poses[end_index] == \"NNP\"):\n",
    "                        proper_noun += (\" \" + words[end_index])\n",
    "                        mention_id = \"%s_%d_%d_%d\" % (docid, sentid, i, end_index)\n",
    "                        end_index += 1\n",
    "                elif poses[i] == \"NNP\":\n",
    "                    end_index = i \n",
    "                    mention_id = \"%s_%d_%d_%d\" % (docid, sentid, i, end_index)\n",
    "                    proper_noun = words[i]\n",
    "                else: \n",
    "                    continue\n",
    "            d.append({\"mention_id\": mention_id, 'docid': docid, 'sentid': sentid, 'begin_index': i, 'end_index': end_index, 'proper_noun': proper_noun})\n",
    "\n",
    "\n",
    "            \n",
    "        #Clear variables: mostly for rerunning in ipython notebook\n",
    "        try:\n",
    "            del end_index\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            del i\n",
    "        except:\n",
    "            continue\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin_index</th>\n",
       "      <th>docid</th>\n",
       "      <th>end_index</th>\n",
       "      <th>mention_id</th>\n",
       "      <th>proper_noun</th>\n",
       "      <th>sentid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>0</td>\n",
       "      <td>54b43277e138239d86852119_43_0_0</td>\n",
       "      <td>Exhumation</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>13</td>\n",
       "      <td>54b43277e138239d86852119_43_13_13</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>18</td>\n",
       "      <td>54b43277e138239d86852119_44_18_18</td>\n",
       "      <td>Strait</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>20</td>\n",
       "      <td>54b43277e138239d86852119_44_20_20</td>\n",
       "      <td>Juan</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>22</td>\n",
       "      <td>54b43277e138239d86852119_44_22_22</td>\n",
       "      <td>Fuca</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>24</td>\n",
       "      <td>54b43277e138239d86852119_44_24_24</td>\n",
       "      <td>Polenz</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>10</td>\n",
       "      <td>54b43277e138239d86852119_46_8_9</td>\n",
       "      <td>Elwha River</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>9</td>\n",
       "      <td>54b43277e138239d86852119_545_7_8</td>\n",
       "      <td>Elwha River</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>54b43277e138239d86852119</td>\n",
       "      <td>10</td>\n",
       "      <td>54b43277e138239d86852119_545_10_10</td>\n",
       "      <td>Washington</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   begin_index                     docid  end_index  \\\n",
       "0            0  54b43277e138239d86852119          0   \n",
       "1           13  54b43277e138239d86852119         13   \n",
       "2           18  54b43277e138239d86852119         18   \n",
       "3           20  54b43277e138239d86852119         20   \n",
       "4           22  54b43277e138239d86852119         22   \n",
       "5           24  54b43277e138239d86852119         24   \n",
       "6            8  54b43277e138239d86852119         10   \n",
       "7            7  54b43277e138239d86852119          9   \n",
       "8           10  54b43277e138239d86852119         10   \n",
       "\n",
       "                           mention_id  proper_noun  sentid  \n",
       "0     54b43277e138239d86852119_43_0_0   Exhumation      43  \n",
       "1   54b43277e138239d86852119_43_13_13      Brandon      43  \n",
       "2   54b43277e138239d86852119_44_18_18       Strait      44  \n",
       "3   54b43277e138239d86852119_44_20_20         Juan      44  \n",
       "4   54b43277e138239d86852119_44_22_22         Fuca      44  \n",
       "5   54b43277e138239d86852119_44_24_24       Polenz      44  \n",
       "6     54b43277e138239d86852119_46_8_9  Elwha River      46  \n",
       "7    54b43277e138239d86852119_545_7_8  Elwha River     545  \n",
       "8  54b43277e138239d86852119_545_10_10   Washington     545  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#returns sentences with work dam in it\n",
    "#cursor.execute(\"select b.* from (select docid, sentid, unnest(words) as word from sentences) a left join sentences b on (a.docid=b.docid AND a.sentid=b.sentid) where (lower(a.word) = 'dam' OR lower(a.word) LIKE '%-dam' OR lower(a.word) LIKE 'dam-%') OR lower(a.word) = 'dams' ;\")\n",
    "\n",
    "#Small query return for testing purposes\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"select * from public.sentences where docid = '54b43277e138239d86852119' and (sentid in (42, 43, 44, 45, 46, 47, 545));\")\n",
    "data = properNouns(cursor)\n",
    "cursor.close()\n",
    "      \n",
    "df=pd.DataFrame(data)\n",
    "df.head(15)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
